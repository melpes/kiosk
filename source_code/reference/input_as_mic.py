import sys
import torch
import numpy as np
import sounddevice as sd
from scipy.io.wavfile import write
from collections import deque
import urllib.error 

#HOW_LONG_RECORD=10   #ìŒì„±íŒŒì¼ ê¸¸ì´ê°€ ë„ˆë¬´ ê¸¸ë©´ STT ê°€ ì•ˆë˜ì§€ ì•Šì„ê¹Œ?



#ë³€ìˆ˜ë“¤
sample_rate = 16000
frame_duration = 0.5    #(ì´ˆ) í•œ ë²ˆì— ì½ì„ ì˜¤ë””ì˜¤ ê¸¸ì´. ì´ê²½ìš°ì—ëŠ” í•œ í”„ë ˆì„ ê¸¸ì´ëŠ” sample_rate 16000 * frame_duration 0.5 ê³±í•´ì„œ 8000ì´ë‹¤.
max_silence_duration_start = 5.0     #(ì´ˆ) ë¬´ìŒì´ ì´ ì‹œê°„ ì´ìƒ ì§€ì†ë˜ë©´ ì¢…ë£Œ
max_silence_duration_end = 3.0
min_record = 1.0     #(ì´ˆ) ìµœì†Œ ë…¹ìŒ ì‹œê°„
vad_threshold=0.2    #vad ë¯¼ê°ë„. ë‚´ ë§ˆì´í¬ëŠ” 0.2ëŠ” ë˜ì•¼ ì˜ ì¸ì‹í•˜ëŠ”ë“¯?
file_name='record.wav'

print('ì•ˆë…•í•˜ì„¸ìš” ë§¥ë„ë‚ ë“œ ì…ë‹ˆë‹¤. ì£¼ë¬¸ì„ ì‹œì‘í•˜ë ¤ë©´ a í‚¤, ì¢…ë£Œí•˜ë ¤ë©´ x í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”')

while True:
    enter=input('ì…ë ¥ : ')
    if enter=='a':
        break
    elif enter=='x':
        print('ì´ìš©í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.')
        sys.exit()
    else:
        print('ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤')
        
##################VAD ë¡œ ìŒì„±ì…ë ¥ì´ ê°ì§€ë˜ëŠ”ì§€ íŒë‹¨

# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
while True:
    try:
        model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad', force_reload=False)   #True ë¡œ í•˜ë©´ ì½”ë“œ ì‹¤í–‰ì‹œí‚¬ë•Œë§ˆë‹¤ ëª¨ë¸ ë‹¤ì‹œë‹¤ìš´ë¡œë“œí•œë‹¤.
    except urllib.error.HTTPError as e:     #github ê°€ ì‘ë‹µ ì•ˆí• ë•Œê°€ ê½¤ ìˆë‹¤.
        continue
    break
(get_speech_timestamps, _, _, _, _) = utils
print('ì£¼ë¬¸ì„ ë§ì”€í•´ì£¼ì„¸ìš”. ë§ì”€ì„ ì‹œì‘í•˜ì‹œë©´ ìë™ìœ¼ë¡œ ë…¹ìŒë©ë‹ˆë‹¤')

# ë…¹ìŒ ë°ì´í„° ì €ì¥ìš©
recorded_frames = []
silence_buffer_start = deque(maxlen=int(max_silence_duration_start / frame_duration))    #max_silence_duration ì´ 3ì´ˆ ì´ê³  frame_duration ì´ 0.5ì´ˆ ë¼ë©´ 3/0.5=6í”„ë ˆì„ ì´ìƒ(ì´ˆê³¼?)ì´ë©´ ë…¹ìŒì¢…ë£Œ.  
silence_buffer_end = deque(maxlen=int(max_silence_duration_end / frame_duration))

stream = sd.InputStream(samplerate=sample_rate, channels=1, dtype='float32', blocksize=int(sample_rate * frame_duration))
stream.start()

try:
    while True:
        audio_block, _ = stream.read(int(sample_rate * frame_duration))
        audio_np = audio_block.squeeze()
        audio_tensor = torch.from_numpy(audio_np)

        # ìŒì„± ê°ì§€. get_speech_timestamps() ëŠ” í…ì„œì—ì„œ ìŒì„±ì´ ìˆëŠ” êµ¬ê°„ì„ ì°¾ì•„ì¤€ë‹¤
        speech = get_speech_timestamps(audio_tensor, model, sampling_rate=sample_rate, threshold=vad_threshold)

        if speech:
            #print("ğŸ—£ï¸ ìŒì„± ê°ì§€ë¨")
            if len(silence_buffer_end)!=0:
                recorded_frames+=list(silence_buffer_end)
                silence_buffer_end.clear()
            recorded_frames.append(audio_np)
        else:
            #print("ğŸ”‡ ë¬´ìŒ")
            if recorded_frames:
                silence_buffer_end.append(audio_np)
            else:
                silence_buffer_start.append(audio_np)

        # ë¬´ìŒì´ ì˜¤ë˜ ì§€ì†ë˜ë©´ ì¢…ë£Œ
        if recorded_frames:
            if len(silence_buffer_end)==silence_buffer_end.maxlen:
                print("ë¬´ìŒì´ ì§€ì†ë˜ì–´ ë…¹ìŒì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
        else:
            if len(silence_buffer_start) == silence_buffer_start.maxlen:
                print('ì…ë ¥ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.')
                sys.exit()
                break
finally:
    stream.stop()
    stream.close()
    
#ì €ì¥
if len(recorded_frames) >= min_record:
    all_audio = np.concatenate(recorded_frames)
    write(f"{file_name}", sample_rate, (all_audio * 32767).astype(np.int16))
    print(f"{file_name} íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
else:
    print('ìŒì„±ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤.')






