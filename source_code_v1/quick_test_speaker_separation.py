#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì‹¤ì œ í™”ìë¶„ë¦¬ ê¸°ëŠ¥ ê°„ë‹¨ í…ŒìŠ¤íŠ¸
"""

import os
import torchaudio
import torch
from pathlib import Path

def create_mixed_audio_sample():
    """ê°„ë‹¨í•œ 2í™”ì ë¯¹ìŠ¤ ì˜¤ë””ì˜¤ ìƒì„±"""
    print("ğŸµ í…ŒìŠ¤íŠ¸ìš© 2í™”ì ë¯¹ìŠ¤ ì˜¤ë””ì˜¤ ìƒì„± ì¤‘...")
    
    # 3ì´ˆ ê¸¸ì´, 16000Hz
    duration = 3.0
    sr = 16000
    t = torch.linspace(0, duration, int(duration * sr))
    
    # í™”ì 1: ë‚®ì€ ì£¼íŒŒìˆ˜ (ë‚¨ì„± ëª©ì†Œë¦¬ ì‹œë®¬ë ˆì´ì…˜)
    speaker1_freq = 150.0  # Hz
    speaker1 = 0.7 * torch.sin(2 * torch.pi * speaker1_freq * t)
    
    # í™”ì 2: ë†’ì€ ì£¼íŒŒìˆ˜ (ì—¬ì„± ëª©ì†Œë¦¬ ì‹œë®¬ë ˆì´ì…˜) 
    speaker2_freq = 300.0  # Hz
    speaker2 = 0.5 * torch.sin(2 * torch.pi * speaker2_freq * t)
    
    # ë¯¹ìŠ¤: í™”ì1ì€ ì „ì²´, í™”ì2ëŠ” ì¤‘ê°„ ë¶€ë¶„ë§Œ
    mixed = speaker1.clone()
    mid_start = int(len(t) * 0.2)
    mid_end = int(len(t) * 0.8)
    mixed[mid_start:mid_end] += speaker2[mid_start:mid_end]
    
    # ë…¸ì´ì¦ˆ ì¶”ê°€
    noise = 0.1 * torch.randn_like(mixed)
    mixed += noise
    
    # ëª¨ë…¸ ì±„ë„ë¡œ ë³€í™˜
    mixed = mixed.unsqueeze(0)  # (1, samples)
    
    # íŒŒì¼ ì €ì¥
    output_path = "test_mixed_audio.wav"
    torchaudio.save(output_path, mixed, sr)
    print(f"âœ… í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤ ìƒì„± ì™„ë£Œ: {output_path}")
    
    return output_path

def test_real_speaker_separation():
    """ì‹¤ì œ í™”ìë¶„ë¦¬ í…ŒìŠ¤íŠ¸"""
    print("ğŸ” ì‹¤ì œ í™”ìë¶„ë¦¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘\n")
    
    try:
        # 1. í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤ ìƒì„±
        test_audio = create_mixed_audio_sample()
        
        # 2. extract_main_speaker í•¨ìˆ˜ ì‹¤í–‰
        print("ğŸš€ í™”ìë¶„ë¦¬ ì‹¤í–‰ ì¤‘...")
        from src.utils.extract_main_speaker_speaking import extract_main_speaker
        
        result_path = extract_main_speaker(
            audiodir=test_audio,
            savedir="separated_speaker.wav"
        )
        
        print(f"âœ… í™”ìë¶„ë¦¬ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {result_path}")
        
        # 3. ê²°ê³¼ íŒŒì¼ ì •ë³´
        if os.path.exists(result_path):
            file_size = os.path.getsize(result_path)
            print(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {file_size:,} bytes ({file_size/1024:.2f} KB)")
            
            # ì˜¤ë””ì˜¤ ì •ë³´
            waveform, sr = torchaudio.load(result_path)
            duration = waveform.shape[1] / sr
            print(f"ğŸµ ì˜¤ë””ì˜¤ ê¸¸ì´: {duration:.2f}ì´ˆ")
            print(f"ğŸ”Š ìƒ˜í”Œë§ ë ˆì´íŠ¸: {sr}Hz")
            print(f"ğŸ“ˆ ì˜¤ë””ì˜¤ shape: {waveform.shape}")
        
        # 4. ì •ë¦¬
        cleanup_files = [test_audio, "separated_speaker.wav", "e_separated_speaker.wav"]
        print(f"\nğŸ§¹ ì„ì‹œ íŒŒì¼ ì •ë¦¬:")
        for file_path in cleanup_files:
            if os.path.exists(file_path):
                os.remove(file_path)
                print(f"  âœ… ì‚­ì œ: {file_path}")
        
        print(f"\nğŸ‰ í™”ìë¶„ë¦¬ í…ŒìŠ¤íŠ¸ ì„±ê³µ! ì‹¤ì œë¡œ ì‘ë™í•©ë‹ˆë‹¤!")
        return True
        
    except Exception as e:
        print(f"âŒ í™”ìë¶„ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        print(f"\nğŸ’¡ ê°€ëŠ¥í•œ ì›ì¸:")
        print(f"  - AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œê°€ í•„ìš”í•¨ (ì²˜ìŒ ì‹¤í–‰ì‹œ ì‹œê°„ ì†Œìš”)")
        print(f"  - GPU ë©”ëª¨ë¦¬ ë¶€ì¡±")
        print(f"  - ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œ (ëª¨ë¸ ë‹¤ìš´ë¡œë“œ)")
        print(f"  - HuggingFace í† í° ë¬¸ì œ")
        return False

if __name__ == "__main__":
    print("=" * 60)
    print("  ì‹¤ì œ í™”ìë¶„ë¦¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("  (AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¡œ ì¸í•´ ì²˜ìŒ ì‹¤í–‰ì‹œ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    print("=" * 60)
    
    success = test_real_speaker_separation()
    
    if success:
        print(f"\nâœ… ê²°ë¡ : extract_main_speaker_speaking.pyê°€ ì‹¤ì œë¡œ ì‘ë™í•©ë‹ˆë‹¤!")
    else:
        print(f"\nâš ï¸  ê²°ë¡ : í™˜ê²½ì€ ì¤€ë¹„ë˜ì—ˆì§€ë§Œ ì‹¤í–‰ ì¤‘ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
        print(f"        ìœ„ì˜ ê°€ëŠ¥í•œ ì›ì¸ë“¤ì„ í™•ì¸í•´ë³´ì„¸ìš”.")