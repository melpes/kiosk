# 학습 데이터 및 모델 파인튜닝 정보

## 데이터 개요
이 프로젝트는 AIHub 011 고객 응대 데이터를 활용하여 Whisper 모델을 파인튜닝합니다. 실제 데이터는 별도의 서버에 존재하며, 이 문서는 데이터 구조와 처리 방법에 대한 참조 정보를 제공합니다.

## 데이터 위치 및 접근
- **데이터 서버 위치**: `/data/aihub011/`
- **데이터 접근 방법**: 별도 서버에 접속하여 데이터 처리 및 모델 학습 수행
- **주의사항**: 현재 프로젝트 폴더에는 데이터가 없으며, 데이터 처리 스크립트도 해당 서버에 존재함

## 데이터셋 구조

### 원본 데이터 구조
```
/data/aihub011/
├── 1.Training/              # 학습용 데이터
├── 2.Validation/            # 검증용 데이터
├── scripts/                 # 데이터 처리 스크립트
└── [처리된 데이터셋 폴더들]
```

### 도메인 분류
- **구매 도메인 (D50)**
  - J01: 카페
  - J02: 식당 (프로젝트 주요 대상)
  - J03: 의류
  - J04: 소매

- **예약 도메인 (D51)**
  - J05: 숙박
  - J06: 학원
  - J07: 독서실
  - J08: 미용실
  - J09: 여행

- **생활 도메인 (D52)**
  - J10: 민원
  - J11: 세탁소
  - J12: 옷수선
  - J13: 여가오락
  - J14: 위치정보

### 처리된 데이터셋
- `dataset_aihub011_D50_J02/`: 식당 도메인 원본 데이터셋
- `dataset_aihub011_D50_J02_processed/`: 오디오 특징 추출 완료
- `dataset_aihub011_D50_J02_processed_tokenized/`: 텍스트 토큰화 완료

## 데이터 처리 파이프라인

### 1. 데이터 준비 (`step1_prepare.py`)
- 오디오 파일(.wav)과 텍스트 파일(.txt) 경로 수집
- 학습/검증 데이터 결합
- HuggingFace Dataset 형태로 변환 및 저장

### 2. 오디오 특징 추출 (`step2_audio_fe.py`)
- Whisper Feature Extractor 사용
- 16kHz로 리샘플링
- Log-Mel spectrogram 변환 (80개 멜 필터뱅크 사용)
- 30초 길이로 패딩 또는 트림하여 표준화된 입력 형태 생성
- 결과: 각 오디오 파일은 (80, 3000) 크기의 특징 행렬로 변환

### 3. 텍스트 토큰화 (`step3_text_tokenize.py`)
- Whisper Tokenizer 사용
- 한국어 설정으로 텍스트를 토큰 ID로 변환
- 시작 토큰 (`<|startoftranscript|>`, `<|ko|>`)과 종료 토큰 (`<|endoftranscript|>`) 추가
- 최대 길이(448 토큰)로 패딩하여 일관된 입력 형태 생성
- 결과: 각 텍스트는 정수 시퀀스로 변환

## Whisper 파인튜닝 설정

### 주요 구성 요소
1. **config.py**: 모델, 데이터셋, 출력 경로 설정
2. **main.py**: 학습 메인 스크립트
3. **preprocessing.py**: 데이터 전처리 및 collator
4. **utils.py**: 유틸리티 함수들

### 학습 설정
- **모델**: `openai/whisper-base`
- **언어**: 한국어
- **메트릭**: CER (Character Error Rate)
- **최대 스텝**: 4000
- **배치 크기**: 192 (train), 16 (eval)

## 권장사항 및 고려사항

1. **데이터 품질 검증**: 오디오-텍스트 쌍의 정확성 확인
2. **도메인별 성능 비교**: 각 도메인(카페, 식당 등)별 모델 성능 분석
3. **하이퍼파라미터 튜닝**: 학습률, 배치 크기 등 최적화
4. **평가 메트릭 다양화**: WER, BLEU 등 추가 메트릭 활용
5. **다중화자인식 통합**: 음성 전처리 단계에서 다중화자인식 기술과의 통합 방안 고려